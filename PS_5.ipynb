{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-QQiMBTrpsR"
      },
      "source": [
        "# PS-3\n",
        "## Name: Atharv Jagdish Patwardhan\n",
        "\n",
        "## Research Topic: Data center placement and it's effects across the USA.\n",
        "With the rise of AI across the world, the demand for high performance computing has increased, creating more demand for datacenters. There datacenters take up large plots of land and consume a lot of energy. In this notebook, we will look at factors that might affect the placement of these datacenters and also the impact they have on the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YohUGWeDT4c7"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio geopandas matplotlib requests folio branca\n",
        "\n",
        "import rasterio\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests, zipfile, io\n",
        "from rasterio.mask import mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W_uLoEGJs8F"
      },
      "outputs": [],
      "source": [
        "base_url = \"https://raw.githubusercontent.com/atharvpatwardhan/Atharv-Patwardhan-GIS-Coursework/main/data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcIBrKWTUgyq"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io, os\n",
        "\n",
        "url = 'https://www.weather.gov/source/gis/Shapefiles/County/s_05mr24.zip'\n",
        "\n",
        "zip_path = \"data/usa_map.zip\"\n",
        "extract_dir = \"data/usa_map\"\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "\n",
        "if not os.path.exists(zip_path):\n",
        "    r = requests.get(url)\n",
        "    with open(zip_path, \"wb\") as f:\n",
        "        f.write(r.content)\n",
        "    print(\"Downloaded USA Map Data\")\n",
        "\n",
        "if not os.path.exists(extract_dir):\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(extract_dir)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sntuBxltUboZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "for f in os.listdir('data/usa_map'):\n",
        "    print(f)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AghyLSiwU6wU"
      },
      "outputs": [],
      "source": [
        "usa_data = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "print(usa_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-5a-hidWQUq"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "usa_data = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "\n",
        "mainland_states = [\n",
        "    \"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"IA\",\"ID\",\"IL\",\"IN\",\n",
        "    \"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\n",
        "    \"NE\",\"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\n",
        "    \"TN\",\"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
        "]\n",
        "\n",
        "mainland_usa = usa_data[usa_data[\"STATE\"].isin(mainland_states)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkqGyO7csILF"
      },
      "source": [
        "## Electricity price and usage\n",
        "As data centers are responsible for hosting everything from websites to cloud storage, they are extremely energy-intensive, accounting for about 2% of global electricity consumption. States with lower electricity costs—such as Washington (where hydroelectric power dominates) and Oregon—are hotspots for data centers, while states like Hawaii, where power costs are high due to reliance on imported fossil fuels, see fewer data center investments.\n",
        "\n",
        "Did you know? The largest data center in the U.S. is the Meta Prinesville facility datacenter located in Prinesville, Oregon, spanning over 4.6 million square feet! It's a fascinating blend of tech, infrastructure, and geography that shapes how and where data centers thrive across the nation.\n",
        "\n",
        "![My Image](https://github.com/atharvpatwardhan/Atharv-Patwardhan-GIS-Coursework/blob/main/images/image.jpeg?raw=true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrug9bRVYBnF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.eia.gov/electricity/data/state/avgprice_annual.xlsx\"\n",
        "\n",
        "electricity_df = pd.read_excel(url, sheet_name=\"Price\", skiprows=1)\n",
        "\n",
        "print(electricity_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAyxrTLcuPmZ"
      },
      "source": [
        "### Looking at the electricity cost per state in the USA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHP3Xc8uZamh"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import folium\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "\n",
        "generation = pd.read_excel(base_url + \"generation_monthly.xlsx\")\n",
        "\n",
        "us_state_map = {\n",
        "    'AL':'Alabama','AK':'Alaska','AZ':'Arizona','AR':'Arkansas','CA':'California',\n",
        "    'CO':'Colorado','CT':'Connecticut','DE':'Delaware','FL':'Florida','GA':'Georgia',\n",
        "    'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas',\n",
        "    'KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MA':'Massachusetts',\n",
        "    'MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana',\n",
        "    'NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico',\n",
        "    'NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma',\n",
        "    'OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina',\n",
        "    'SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont',\n",
        "    'VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'\n",
        "}\n",
        "generation['State'] = generation['STATE'].map(us_state_map)\n",
        "\n",
        "generation_state = (\n",
        "    generation.groupby('State', as_index=False)['GENERATION (Megawatthours)']\n",
        "    .sum()\n",
        "    .rename(columns={'GENERATION (Megawatthours)': 'Generation_MWh'})\n",
        ")\n",
        "\n",
        "merged_geo = usa_states.merge(generation_state, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n",
        "def load_datacenters(path, company):\n",
        "    df = pd.read_csv(path)\n",
        "    df = df[df[\"Country\"].str.lower().str.strip() == \"united states\"]\n",
        "    df = df[(df[\"Latitude\"] != \"-\") & (df[\"Longitude\"] != \"-\")]\n",
        "    df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
        "    df[\"Longitude\"] = df[\"Longitude\"].astype(float)\n",
        "    df[\"Company\"] = company\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df,\n",
        "        geometry=gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    return gdf\n",
        "\n",
        "amazon_gdf = load_datacenters(base_url + \"amazon_data_centers.csv\", \"Amazon\")\n",
        "google_gdf = load_datacenters(base_url + \"google_data_centers.csv\", \"Google\")\n",
        "meta_gdf = load_datacenters(base_url + \"meta_data_centers.csv\", \"Meta\")\n",
        "microsoft_gdf = load_datacenters(base_url + \"microsoft_data_centers.csv\", \"Microsoft\")\n",
        "\n",
        "datacenters = pd.concat([amazon_gdf, google_gdf, meta_gdf, microsoft_gdf])\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"cartodb positron\")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=merged_geo,\n",
        "    name=\"Electricity Generation (MWh)\",\n",
        "    data=merged_geo,\n",
        "    columns=[\"NAME\", \"Generation_MWh\"],\n",
        "    key_on=\"feature.properties.NAME\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.8,\n",
        "    line_opacity=0.3,\n",
        "    legend_name=\"Electricity Generation (MWh)\"\n",
        ").add_to(m)\n",
        "\n",
        "company_colors = {\n",
        "    \"Amazon\": \"blue\",\n",
        "    \"Google\": \"green\",\n",
        "    \"Meta\": \"purple\",\n",
        "    \"Microsoft\": \"orange\"\n",
        "}\n",
        "\n",
        "for company, color in company_colors.items():\n",
        "    company_df = datacenters[datacenters[\"Company\"] == company]\n",
        "    for _, row in company_df.iterrows():\n",
        "        popup_html = f\"\"\"\n",
        "        <b>{company} Data Center</b><br>\n",
        "        Location: {row.get('City', 'Unknown')}<br>\n",
        "        Lat: {row['Latitude']:.2f}, Lon: {row['Longitude']:.2f}\n",
        "        \"\"\"\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "            radius=6,\n",
        "            color=\"black\",\n",
        "            fill=True,\n",
        "            fill_color=color,\n",
        "            fill_opacity=0.8,\n",
        "            popup=popup_html\n",
        "        ).add_to(m)\n",
        "\n",
        "legend_html = \"\"\"\n",
        "<div style=\"\n",
        "     position: fixed;\n",
        "     bottom: 40px; left: 40px; width: 250px; height: 140px;\n",
        "     background-color: white; border:2px solid grey; z-index:9999; font-size:14px;\n",
        "     box-shadow: 2px 2px 5px rgba(0,0,0,0.3); padding: 10px;\">\n",
        "<b>Legend</b><br>\n",
        "<span style=\"background-color:#ffcc00;width:20px;height:20px;display:inline-block;margin-right:5px;\"></span> Electricity Generation<br>\n",
        "<span style=\"background-color:blue;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Amazon<br>\n",
        "<span style=\"background-color:green;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Google<br>\n",
        "<span style=\"background-color:purple;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Meta<br>\n",
        "<span style=\"background-color:orange;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Microsoft\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "m.save(\"interactive_map.html\")\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6fc1179"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('interactive_map.html')\n",
        "files.download('unemployment_datacenters_map.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTsGlw2p5C8F"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.eia.gov/electricity/data/state/avgprice_annual.xlsx\"\n",
        "\n",
        "electricity_df = pd.read_excel(url, sheet_name=\"Price\", skiprows=1)\n",
        "\n",
        "electricity_df.head()\n",
        "electricity_df.rename(columns={\"State\": \"STATE\"}, inplace=True)\n",
        "electricity_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7sS6elav6D9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dc_df = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "\n",
        "us_abbrev = {\n",
        "    \"Alabama\":\"AL\", \"Alaska\":\"AK\", \"Arizona\":\"AZ\", \"Arkansas\":\"AR\", \"California\":\"CA\", \"Colorado\":\"CO\",\n",
        "    \"Connecticut\":\"CT\", \"Delaware\":\"DE\", \"Florida\":\"FL\", \"Georgia\":\"GA\", \"Hawaii\":\"HI\", \"Idaho\":\"ID\",\n",
        "    \"Illinois\":\"IL\", \"Indiana\":\"IN\", \"Iowa\":\"IA\", \"Kansas\":\"KS\", \"Kentucky\":\"KY\", \"Louisiana\":\"LA\",\n",
        "    \"Maine\":\"ME\", \"Maryland\":\"MD\", \"Massachusetts\":\"MA\", \"Michigan\":\"MI\", \"Minnesota\":\"MN\",\n",
        "    \"Mississippi\":\"MS\", \"Missouri\":\"MO\", \"Montana\":\"MT\", \"Nebraska\":\"NE\", \"Nevada\":\"NV\",\n",
        "    \"New Hampshire\":\"NH\", \"New Jersey\":\"NJ\", \"New Mexico\":\"NM\", \"New York\":\"NY\", \"North Carolina\":\"NC\",\n",
        "    \"North Dakota\":\"ND\", \"Ohio\":\"OH\", \"Oklahoma\":\"OK\", \"Oregon\":\"OR\", \"Pennsylvania\":\"PA\",\n",
        "    \"Rhode Island\":\"RI\", \"South Carolina\":\"SC\", \"South Dakota\":\"SD\", \"Tennessee\":\"TN\", \"Texas\":\"TX\",\n",
        "    \"Utah\":\"UT\", \"Vermont\":\"VT\", \"Virginia\":\"VA\", \"Washington\":\"WA\", \"West Virginia\":\"WV\",\n",
        "    \"Wisconsin\":\"WI\", \"Wyoming\":\"WY\"\n",
        "}\n",
        "dc_df[\"STATE\"] = dc_df[\"State\"].map(us_abbrev)\n",
        "\n",
        "merged_electricity = pd.merge(dc_df, electricity_df, on=\"STATE\", how=\"left\")\n",
        "\n",
        "merged_electricity.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import folium\n",
        "from branca.colormap import linear\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "centroids = usa_states.geometry.centroid\n",
        "usa_states[\"centroid_lat\"] = centroids.y\n",
        "usa_states[\"centroid_lon\"] = centroids.x\n",
        "\n",
        "elec_price_state = (\n",
        "    merged_electricity[merged_electricity[\"Industry Sector Category\"] == \"Total Electric Industry\"]\n",
        "    .groupby(\"State\", as_index=False)[\"Commercial\"]\n",
        "    .mean()\n",
        "    .rename(columns={\"Commercial\": \"ElectricityPrice\"})\n",
        ")\n",
        "\n",
        "\n",
        "dc_count_state = (\n",
        "    merged_electricity.groupby(\"State\", as_index=False)[\"DataCenters\"]\n",
        "    .max()\n",
        ")\n",
        "\n",
        "map_df = elec_price_state.merge(dc_count_state, on=\"State\", how=\"left\")\n",
        "geo_map_df = usa_states.merge(map_df, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"CartoDB Positron\")\n",
        "\n",
        "\n",
        "colormap = linear.YlOrRd_09.scale(\n",
        "    geo_map_df[\"ElectricityPrice\"].min(),\n",
        "    geo_map_df[\"ElectricityPrice\"].max()\n",
        ")\n",
        "colormap.caption = \"Electricity Price (cents per kWh)\"\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=geo_map_df,\n",
        "    name=\"Electricity Price (Commercial)\",\n",
        "    data=geo_map_df,\n",
        "    columns=[\"NAME\", \"ElectricityPrice\"],\n",
        "    key_on=\"feature.properties.NAME\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.85,\n",
        "    line_opacity=0.5,\n",
        "    legend_name=\"Electricity Price (cents per kWh)\"\n",
        ").add_to(m)\n",
        "\n",
        "colormap.add_to(m)\n",
        "\n",
        "\n",
        "max_dc = geo_map_df[\"DataCenters\"].max()\n",
        "for _, row in geo_map_df.iterrows():\n",
        "    if pd.notnull(row[\"DataCenters\"]):\n",
        "        color = \"red\"\n",
        "        radius = 5 + (row[\"DataCenters\"] ** 0.5)\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "            radius=radius,\n",
        "            color=\"red\",\n",
        "            fill=True,\n",
        "            fill_color=color,\n",
        "            fill_opacity=1,\n",
        "            popup=f\"{row['NAME']}<br>Datacenters: {int(row['DataCenters'])}<br>Electricity Price: {row['ElectricityPrice']:.2f}\"\n",
        "        ).add_to(m)\n",
        "\n",
        "\n",
        "legend_html = \"\"\"\n",
        "<div style=\"\n",
        "     position: fixed; bottom: 40px; left: 40px; width:260px;\n",
        "     background:white; border:2px solid grey; z-index:9999;\n",
        "     font-size:14px; padding:12px; border-radius:10px;\">\n",
        "<b>Legend</b><br>\n",
        "<span style=\"background: linear-gradient(to right, yellow, red); width:50px; height:15px;\n",
        "      display:inline-block; margin-right:8px;\"></span> Datacenter Count (circle size & color)\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "\n",
        "m.save(\"datacenter_price_map.html\")\n",
        "m\n"
      ],
      "metadata": {
        "id": "shaUVPGopIix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8r_7b5bwy7b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "datacenters_df = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "electricity_df = pd.read_excel(base_url + \"generation_monthly.xlsx\")\n",
        "\n",
        "us_state_map = {\n",
        "    'AL':'Alabama','AK':'Alaska','AZ':'Arizona','AR':'Arkansas','CA':'California',\n",
        "    'CO':'Colorado','CT':'Connecticut','DE':'Delaware','FL':'Florida','GA':'Georgia',\n",
        "    'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas',\n",
        "    'KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MA':'Massachusetts',\n",
        "    'MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana',\n",
        "    'NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico',\n",
        "    'NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma',\n",
        "    'OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina',\n",
        "    'SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont',\n",
        "    'VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'\n",
        "}\n",
        "\n",
        "electricity_df['State'] = electricity_df['STATE'].map(us_state_map)\n",
        "\n",
        "electricity_state = (\n",
        "    electricity_df.groupby('State', as_index=False)['GENERATION (Megawatthours)']\n",
        "    .sum()\n",
        "    .rename(columns={'GENERATION (Megawatthours)': 'Generation_MWh'})\n",
        ")\n",
        "\n",
        "merged_df = pd.merge(datacenters_df, electricity_state, on='State', how='left')\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "\n",
        "merged_geo = usa_states.merge(merged_df, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 9))\n",
        "ax.set_facecolor(\"#F9F9F9\")\n",
        "\n",
        "merged_geo.plot(\n",
        "    column='Generation_MWh',\n",
        "    cmap='YlGnBu',  # teal-blue map\n",
        "    linewidth=0.8,\n",
        "    ax=ax,\n",
        "    edgecolor='white',\n",
        "    legend=True,\n",
        "    legend_kwds={'label': \"Electricity Generation (MWh)\", 'shrink': 0.6}\n",
        ")\n",
        "\n",
        "norm = Normalize(vmin=merged_geo['DataCenters'].min(), vmax=merged_geo['DataCenters'].max())\n",
        "cmap = plt.cm.Reds\n",
        "\n",
        "for _, row in merged_geo.dropna(subset=['DataCenters']).iterrows():\n",
        "    plt.scatter(\n",
        "        row.geometry.centroid.x,\n",
        "        row.geometry.centroid.y,\n",
        "        s=120,  # constant radius\n",
        "        color=cmap(norm(row['DataCenters'])),\n",
        "        alpha=0.75,\n",
        "        edgecolor='black',\n",
        "        linewidth=0.5\n",
        "    )\n",
        "\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "sm._A = []  # required for colorbar\n",
        "cbar = plt.colorbar(sm, ax=ax, shrink=0.6, pad=0.02)\n",
        "cbar.set_label(\"Data Center Count\", fontsize=10)\n",
        "\n",
        "plt.title(\n",
        "    \"U.S. Electricity Generation vs Data Center Presence by State\",\n",
        "    fontsize=17,\n",
        "    weight='bold',\n",
        "    pad=20\n",
        ")\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned = merged_electricity[\n",
        "    merged_electricity['Industry Sector Category'] == 'Total Electric Industry'\n",
        "]\n",
        "\n",
        "cleaned = cleaned[['State', 'DataCenters', 'Total']].reset_index(drop=True)\n",
        "\n",
        "cleaned = cleaned.rename(columns={'Total': 'avg_price'})\n"
      ],
      "metadata": {
        "id": "luv7GzrLrU89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = cleaned.copy()\n",
        "\n",
        "# Compute quadrant thresholds\n",
        "price_med = df['avg_price'].median()\n",
        "dc_med = df['DataCenters'].median()\n",
        "\n",
        "def classify(row):\n",
        "    if row['avg_price'] >= price_med and row['DataCenters'] >= dc_med:\n",
        "        return \"High Price / High DC Count\"\n",
        "    elif row['avg_price'] < price_med and row['DataCenters'] >= dc_med:\n",
        "        return \"Low Price / High DC Count\"\n",
        "    elif row['avg_price'] >= price_med and row['DataCenters'] < dc_med:\n",
        "        return \"High Price / Low DC Count\"\n",
        "    else:\n",
        "        return \"Low Price / Low DC Count\"\n",
        "\n",
        "df['Quadrant'] = df.apply(classify, axis=1)\n",
        "\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"avg_price\",\n",
        "    y=\"DataCenters\",\n",
        "    color=\"Quadrant\",\n",
        "    hover_name=\"State\",\n",
        "    hover_data={\n",
        "        \"avg_price\": True,\n",
        "        \"DataCenters\": True,\n",
        "        \"Quadrant\": True\n",
        "    },\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2,\n",
        "    height=700,\n",
        "    size=[12]*len(df)\n",
        ")\n",
        "\n",
        "fig.add_vline(x=price_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "fig.add_hline(y=dc_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Electricity Price vs Data Centers (Hover to See State)\",\n",
        "    xaxis_title=\"Electricity Price (cents per kWh)\",\n",
        "    yaxis_title=\"Data Centers\",\n",
        "    plot_bgcolor=\"rgba(245,245,245,0.3)\",\n",
        "    legend_title=\"Quadrant\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "7Vsi9PApqsRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW1p7heLbhGn"
      },
      "source": [
        "## Datacenters and Unemployment\n",
        "\n",
        "### This study investigates the relationship between data center locations and unemployment rates across U.S. states, exploring whether the rise of digital infrastructure contributes to local job markets. While data centers themselves are not major employers—often requiring only a few dozen permanent staff once operational—they can have a significant indirect economic impact. Their construction phases create hundreds of temporary jobs, and their presence often attracts tech companies, cloud service providers, and infrastructure suppliers to the region."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0s6fRQwnblQS"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "\n",
        "ers_csv_url = \"https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/48747/Unemployment2023.csv\"\n",
        "\n",
        "resp = requests.get(ers_csv_url)\n",
        "resp.raise_for_status()\n",
        "ers_df = pd.read_csv(BytesIO(resp.content))\n",
        "\n",
        "print(ers_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzXnYa1ub8dT"
      },
      "outputs": [],
      "source": [
        "ers_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "168FE3y3cuJP"
      },
      "outputs": [],
      "source": [
        "ers_pivot = ers_df.pivot_table(\n",
        "    index=\"State\",\n",
        "    columns=\"Attribute\",\n",
        "    values=\"Value\",\n",
        "    aggfunc=\"first\"\n",
        ").reset_index()\n",
        "\n",
        "ers_pivot.columns.name = None\n",
        "ers_pivot = ers_pivot.rename(columns={\"State\": \"STATE\"})\n",
        "ers_pivot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl4QG8lp2rsT"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import folium\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "\n",
        "us_state_map = {\n",
        "    'AL':'Alabama','AK':'Alaska','AZ':'Arizona','AR':'Arkansas','CA':'California',\n",
        "    'CO':'Colorado','CT':'Connecticut','DE':'Delaware','FL':'Florida','GA':'Georgia',\n",
        "    'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas',\n",
        "    'KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MA':'Massachusetts',\n",
        "    'MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana',\n",
        "    'NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico',\n",
        "    'NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma',\n",
        "    'OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina',\n",
        "    'SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont',\n",
        "    'VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'\n",
        "}\n",
        "\n",
        "ers_pivot[\"State\"] = ers_pivot[\"STATE\"].map(us_state_map)\n",
        "merged_geo = usa_states.merge(ers_pivot, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n",
        "def load_datacenters(path, company):\n",
        "    df = pd.read_csv(path)\n",
        "    df = df[df[\"Country\"].str.lower().str.strip() == \"united states\"]\n",
        "    df = df[(df[\"Latitude\"] != \"-\") & (df[\"Longitude\"] != \"-\")]\n",
        "    df[\"Latitude\"] = df[\"Latitude\"].astype(float)\n",
        "    df[\"Longitude\"] = df[\"Longitude\"].astype(float)\n",
        "    df[\"Company\"] = company\n",
        "    gdf = gpd.GeoDataFrame(\n",
        "        df,\n",
        "        geometry=gpd.points_from_xy(df[\"Longitude\"], df[\"Latitude\"]),\n",
        "        crs=\"EPSG:4326\"\n",
        "    )\n",
        "    return gdf\n",
        "\n",
        "amazon_gdf = load_datacenters(base_url + \"amazon_data_centers.csv\", \"Amazon\")\n",
        "google_gdf = load_datacenters(base_url + \"google_data_centers.csv\", \"Google\")\n",
        "meta_gdf = load_datacenters(base_url + \"meta_data_centers.csv\", \"Meta\")\n",
        "microsoft_gdf = load_datacenters(base_url + \"microsoft_data_centers.csv\", \"Microsoft\")\n",
        "\n",
        "datacenters = pd.concat([amazon_gdf, google_gdf, meta_gdf, microsoft_gdf])\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"cartodb positron\")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=merged_geo,\n",
        "    name=\"Unemployment Rate (2023)\",\n",
        "    data=merged_geo,\n",
        "    columns=[\"NAME\", \"Unemployment_rate_2023\"],\n",
        "    key_on=\"feature.properties.NAME\",\n",
        "    fill_color=\"PuBuGn\",\n",
        "    fill_opacity=0.8,\n",
        "    line_opacity=0.3,\n",
        "    legend_name=\"Unemployment Rate (2023)\",\n",
        ").add_to(m)\n",
        "\n",
        "company_colors = {\n",
        "    \"Amazon\": \"#1f77b4\",\n",
        "    \"Google\": \"#2ca02c\",\n",
        "    \"Meta\": \"#9467bd\",\n",
        "    \"Microsoft\": \"#ff7f0e\"\n",
        "}\n",
        "\n",
        "for company, color in company_colors.items():\n",
        "    company_df = datacenters[datacenters[\"Company\"] == company]\n",
        "    for _, row in company_df.iterrows():\n",
        "        popup_html = f\"\"\"\n",
        "        <b>{company} Data Center</b><br>\n",
        "        Location: {row.get('City', 'Unknown')}<br>\n",
        "        Lat: {row['Latitude']:.2f}, Lon: {row['Longitude']:.2f}\n",
        "        \"\"\"\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"Latitude\"], row[\"Longitude\"]],\n",
        "            radius=6,\n",
        "            color=\"black\",\n",
        "            fill=True,\n",
        "            fill_color=color,\n",
        "            fill_opacity=0.85,\n",
        "            popup=popup_html\n",
        "        ).add_to(m)\n",
        "\n",
        "legend_html = \"\"\"\n",
        "<div style=\"\n",
        "     position: fixed;\n",
        "     bottom: 40px; left: 40px; width: 260px; height: 160px;\n",
        "     background-color: white; border:2px solid grey; z-index:9999; font-size:14px;\n",
        "     box-shadow: 2px 2px 5px rgba(0,0,0,0.3); padding: 10px;\">\n",
        "<b>Legend</b><br>\n",
        "<span style=\"background-color:#6baed6;width:20px;height:20px;display:inline-block;margin-right:5px;\"></span> Unemployment Rate<br>\n",
        "<span style=\"background-color:#1f77b4;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Amazon<br>\n",
        "<span style=\"background-color:#2ca02c;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Google<br>\n",
        "<span style=\"background-color:#9467bd;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Meta<br>\n",
        "<span style=\"background-color:#ff7f0e;width:15px;height:15px;border-radius:50%;display:inline-block;margin-right:5px;\"></span> Microsoft\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "m.save(\"unemployment_datacenters_map.html\")\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsKkVyKHzy-M"
      },
      "outputs": [],
      "source": [
        "dc_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irEtmwuwz3-Y"
      },
      "outputs": [],
      "source": [
        "ers_pivot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AebSd2MQzdts"
      },
      "outputs": [],
      "source": [
        "df_merged = pd.merge(dc_df, ers_pivot, on=\"STATE\", how=\"left\")\n",
        "df_merged.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7dJOJDI0HAi"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = px.choropleth(\n",
        "    df_merged,\n",
        "    locations=\"STATE\",\n",
        "    locationmode=\"USA-states\",\n",
        "    color=\"Unemployment_rate_2023\",\n",
        "    color_continuous_scale=\"PuBuGn\",\n",
        "    scope=\"usa\",\n",
        "    title=\"U.S. Unemployment Rate vs Data Center Presence by State\",\n",
        "    labels={\"Unemployment_rate_2023\": \"Unemployment Rate (%)\"}\n",
        ")\n",
        "\n",
        "fig.add_scattergeo(\n",
        "    locations=df_merged[\"STATE\"],\n",
        "    locationmode=\"USA-states\",\n",
        "    text=df_merged[\"STATE\"],\n",
        "    marker=dict(\n",
        "        size=df_merged[\"DataCenters\"] / df_merged[\"DataCenters\"].max() * 35 + 6,\n",
        "        color=\"cyan\",\n",
        "        opacity=0.85,\n",
        "        line=dict(width=0.8, color=\"white\")\n",
        "    ),\n",
        "    name=\"Data Centers\"\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    geo=dict(\n",
        "        scope=\"usa\",\n",
        "        projection_type=\"albers usa\",\n",
        "        showland=True,\n",
        "        landcolor=\"rgb(245, 245, 245)\",\n",
        "        subunitcolor=\"white\",\n",
        "        showlakes=True,\n",
        "        lakecolor=\"rgb(230, 230, 230)\"\n",
        "    ),\n",
        "    title_x=0.5,\n",
        "    title_font=dict(size=20, family=\"Arial Black\"),\n",
        "    margin=dict(r=0, t=60, l=0, b=0),\n",
        "    coloraxis_colorbar=dict(\n",
        "        title=\"Unemployment Rate (%)\",\n",
        "        tickfont=dict(size=12),\n",
        "        titlefont=dict(size=14)\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = df_merged.copy()\n",
        "\n",
        "df = df[['State_x', 'DataCenters', 'Unemployment_rate_2023']].dropna()\n",
        "\n",
        "df.rename(columns={\n",
        "    'State_x': 'State',\n",
        "    'Unemployment_rate_2023': 'Unemployment'\n",
        "}, inplace=True)\n",
        "\n",
        "unemp_med = df['Unemployment'].median()\n",
        "dc_med = df['DataCenters'].median()\n",
        "\n",
        "def classify(row):\n",
        "    if row['Unemployment'] >= unemp_med and row['DataCenters'] >= dc_med:\n",
        "        return \"High Unemployment / High DC Count\"\n",
        "    elif row['Unemployment'] < unemp_med and row['DataCenters'] >= dc_med:\n",
        "        return \"Low Unemployment / High DC Count\"\n",
        "    elif row['Unemployment'] >= unemp_med and row['DataCenters'] < dc_med:\n",
        "        return \"High Unemployment / Low DC Count\"\n",
        "    else:\n",
        "        return \"Low Unemployment / Low DC Count\"\n",
        "\n",
        "df['Quadrant'] = df.apply(classify, axis=1)\n",
        "\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"Unemployment\",\n",
        "    y=\"DataCenters\",\n",
        "    color=\"Quadrant\",\n",
        "    hover_name=\"State\",\n",
        "    hover_data={\n",
        "        \"Unemployment\": True,\n",
        "        \"DataCenters\": True,\n",
        "        \"Quadrant\": True\n",
        "    },\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2,\n",
        "    height=700,\n",
        "    size=[12]*len(df)\n",
        ")\n",
        "\n",
        "fig.add_vline(x=unemp_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "fig.add_hline(y=dc_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Unemployment Rate (2023) vs Data Centers — Quadrant Classifier\",\n",
        "    xaxis_title=\"Unemployment Rate (2023, %)\",\n",
        "    yaxis_title=\"Data Center Count\",\n",
        "    plot_bgcolor=\"rgba(245,245,245,0.3)\",\n",
        "    legend_title=\"Quadrant\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "901b1ImNr9Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4JiRd2D6Pq0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "ers_pivot[\"Unemployment_rate_2023\"] = pd.to_numeric(ers_pivot[\"Unemployment_rate_2023\"], errors=\"coerce\")\n",
        "\n",
        "unemp_latest = ers_pivot[[\"STATE\", \"Unemployment_rate_2023\"]].rename(columns={\"STATE\": \"State_Abbr\"})\n",
        "\n",
        "merged = pd.merge(dc_df, unemp_latest, left_on=\"STATE\", right_on=\"State_Abbr\", how=\"left\")\n",
        "\n",
        "merged = merged.drop(columns=[\"State_Abbr\"])\n",
        "merged.head()\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "plot = sns.jointplot(\n",
        "    x=merged[\"DataCenters\"],\n",
        "    y=merged[\"Unemployment_rate_2023\"],\n",
        "    kind=\"reg\",\n",
        "    color=\"#2E86AB\",\n",
        "    height=6\n",
        ")\n",
        "\n",
        "plot.set_axis_labels(\n",
        "    xlabel=\"Number of Data Centers\",\n",
        "    ylabel=\"Unemployment Rate (2023, %)\"\n",
        ")\n",
        "plot.fig.suptitle(\n",
        "    \"Relationship Between Number of Data Centers and Unemployment Rate (2023)\",\n",
        "    fontsize=13\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro42k5kO6GoG"
      },
      "source": [
        "### We observe that there is no extreme unemployment in the states where data centers exist. Though there is no obvious correlation between unemployment and number of datacenters, the more datacenters in a state, the less the unemployment is the overall trend, California being the exception.\n",
        "\n",
        "### Most employment is generated during the construction of datacenters. Once the datacenter is built, not a lot of people are needed to operate them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt-SK8-YdPz6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Literacy dataset\n",
        "literacy = pd.read_csv(base_url + 'literacy_rates.csv')\n",
        "literacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx6vz6VddTCk"
      },
      "outputs": [],
      "source": [
        "unemployment = pd.read_csv(\"https://ers.usda.gov/sites/default/files/_laserfiche/DataFiles/48747/Unemployment2023.csv\")\n",
        "unemployment.rename(columns={\"State\": \"State\", \"Unemployment\": \"UnemploymentRate\"}, inplace=True)\n",
        "unemployment_pivot = unemployment.pivot_table(\n",
        "    index=\"State\",\n",
        "    columns=\"Attribute\",\n",
        "    values=\"Value\",\n",
        "    aggfunc=\"first\"\n",
        ").reset_index()\n",
        "\n",
        "us_state_map = {\n",
        "    'AL':'Alabama','AK':'Alaska','AZ':'Arizona','AR':'Arkansas','CA':'California',\n",
        "    'CO':'Colorado','CT':'Connecticut','DE':'Delaware','FL':'Florida','GA':'Georgia',\n",
        "    'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas',\n",
        "    'KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MA':'Massachusetts',\n",
        "    'MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana',\n",
        "    'NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico',\n",
        "    'NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma',\n",
        "    'OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina',\n",
        "    'SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont',\n",
        "    'VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'\n",
        "}\n",
        "\n",
        "unemployment_pivot[\"State\"] = unemployment_pivot[\"State\"].map(us_state_map)\n",
        "\n",
        "unemployment_pivot.columns.name = None\n",
        "unemployment_pivot.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxnEtfm0c3_F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "unemployment_literacy_merged = literacy.merge(unemployment_pivot, on=\"State\", how=\"inner\")\n",
        "unemployment_literacy_merged.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WC0jghKggNy"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "\n",
        "geojson_url = \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/us-states.json\"\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"CartoDB positron\")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=geojson_url,\n",
        "    name=\"Literacy Rate\",\n",
        "    data=unemployment_literacy_merged,\n",
        "    columns=[\"State\", \"LiteracyRate\"],\n",
        "    key_on=\"feature.properties.name\",\n",
        "    fill_color=\"YlGnBu\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Literacy Rate Score\"\n",
        ").add_to(m)\n",
        "\n",
        "for _, row in unemployment_literacy_merged.iterrows():\n",
        "    folium.Marker(\n",
        "        location=[row[\"Latitude\"], row[\"Longitude\"]] if \"Latitude\" in unemployment_literacy_merged.columns else None,\n",
        "        popup=f\"<b>{row['State']}</b><br>Literacy: {row['LiteracyRate']}<br>Unemployment: {row['Unemployment_rate_2023']}%\"\n",
        "    )\n",
        "\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91LBGqZUhAR4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(unemployment_literacy_merged[\"LiteracyRate\"], unemployment_literacy_merged[\"Unemployment_rate_2023\"], s=80)\n",
        "\n",
        "for _, row in unemployment_literacy_merged.iterrows():\n",
        "    plt.text(row[\"LiteracyRate\"] + 0.1, row[\"Unemployment_rate_2023\"] + 0.02, row[\"State\"])\n",
        "\n",
        "plt.xlabel(\"Literacy Rate (Score)\")\n",
        "plt.ylabel(\"Unemployment Rate (%)\")\n",
        "plt.title(\"Literacy Rate vs Unemployment Rate (State-level)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = unemployment_literacy_merged.copy()\n",
        "\n",
        "# Select relevant columns\n",
        "df = df[['State', 'LiteracyRate', 'Unemployment_rate_2023']].dropna()\n",
        "\n",
        "df.rename(columns={\n",
        "    'Unemployment_rate_2023': 'Unemployment'\n",
        "}, inplace=True)\n",
        "\n",
        "# Compute medians for quadrant classification\n",
        "lit_med = df['LiteracyRate'].median()\n",
        "unemp_med = df['Unemployment'].median()\n",
        "\n",
        "# Quadrant classification\n",
        "def classify(row):\n",
        "    if row['LiteracyRate'] >= lit_med and row['Unemployment'] >= unemp_med:\n",
        "        return \"High Literacy / High Unemployment\"\n",
        "    elif row['LiteracyRate'] >= lit_med and row['Unemployment'] < unemp_med:\n",
        "        return \"High Literacy / Low Unemployment\"\n",
        "    elif row['LiteracyRate'] < lit_med and row['Unemployment'] >= unemp_med:\n",
        "        return \"Low Literacy / High Unemployment\"\n",
        "    else:\n",
        "        return \"Low Literacy / Low Unemployment\"\n",
        "\n",
        "df['Quadrant'] = df.apply(classify, axis=1)\n",
        "\n",
        "# Build scatter plot\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"LiteracyRate\",\n",
        "    y=\"Unemployment\",\n",
        "    color=\"Quadrant\",\n",
        "    hover_name=\"State\",\n",
        "    hover_data={\n",
        "        \"LiteracyRate\": True,\n",
        "        \"Unemployment\": True,\n",
        "        \"Quadrant\": True\n",
        "    },\n",
        "    color_discrete_sequence=px.colors.qualitative.Set2,\n",
        "    height=700,\n",
        "    size=[12] * len(df)\n",
        ")\n",
        "\n",
        "# Add median lines\n",
        "fig.add_vline(x=lit_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "fig.add_hline(y=unemp_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Literacy Rate vs Unemployment Rate (2023) — Quadrant Classifier\",\n",
        "    xaxis_title=\"Literacy Rate\",\n",
        "    yaxis_title=\"Unemployment Rate (%)\",\n",
        "    plot_bgcolor=\"rgba(245,245,245,0.3)\",\n",
        "    legend_title=\"Quadrant\"\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "dpIp-e1xsQrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_lit = unemployment_literacy_merged.copy()\n",
        "df_dc = df_merged[['State_x', 'DataCenters']].copy().rename(columns={'State_x': 'State'})\n",
        "\n",
        "# merge on state name\n",
        "df3 = df_lit.merge(df_dc, on='State', how='left')\n",
        "\n",
        "# keep only needed columns\n",
        "df3 = df3[['State', 'LiteracyRate', 'Unemployment_rate_2023', 'DataCenters']].dropna()\n",
        "\n",
        "df3.rename(columns={'Unemployment_rate_2023': 'Unemployment'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "uT7ogDYssV_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    df3,\n",
        "    x=\"LiteracyRate\",\n",
        "    y=\"Unemployment\",\n",
        "    z=\"DataCenters\",\n",
        "    color=\"DataCenters\",\n",
        "    color_continuous_scale=\"Viridis\",\n",
        "    hover_name=\"State\",\n",
        "    hover_data={\n",
        "        \"LiteracyRate\": True,\n",
        "        \"Unemployment\": True,\n",
        "        \"DataCenters\": True\n",
        "    },\n",
        "    height=800,\n",
        "    size=[8] * len(df3),\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"3D Scatterplot: Literacy Rate vs Unemployment vs Data Center Count\",\n",
        "    scene=dict(\n",
        "        xaxis_title=\"Literacy Rate\",\n",
        "        yaxis_title=\"Unemployment Rate (%)\",\n",
        "        zaxis_title=\"Data Center Count\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Lm9eQO52sYhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import folium\n",
        "from branca.colormap import linear\n",
        "\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "\n",
        "centroids = usa_states.geometry.centroid\n",
        "usa_states[\"centroid_lat\"] = centroids.y\n",
        "usa_states[\"centroid_lon\"] = centroids.x\n",
        "\n",
        "\n",
        "map_df = unemployment_literacy_merged[[\"State\", \"LiteracyRate\", \"Unemployment_rate_2023\"]]\n",
        "\n",
        "geo_map_df = usa_states.merge(map_df, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"CartoDB Positron\")\n",
        "\n",
        "colormap_lit = linear.BuPu_09.scale(\n",
        "    geo_map_df[\"LiteracyRate\"].min(),\n",
        "    geo_map_df[\"LiteracyRate\"].max()\n",
        ")\n",
        "colormap_lit.caption = \"Literacy Rate\"\n",
        "folium.Choropleth(\n",
        "    geo_data=geo_map_df,\n",
        "    name=\"Literacy Rate\",\n",
        "    data=geo_map_df,\n",
        "    columns=[\"NAME\", \"LiteracyRate\"],\n",
        "    key_on=\"feature.properties.NAME\",\n",
        "    fill_color=\"BuPu\",\n",
        "    fill_opacity=0.8,\n",
        "    line_opacity=0.5,\n",
        "    legend_name=\"Literacy Rate\"\n",
        ").add_to(m)\n",
        "\n",
        "colormap_lit.add_to(m)\n",
        "\n",
        "\n",
        "max_unemp = geo_map_df[\"Unemployment_rate_2023\"].max()\n",
        "\n",
        "for _, row in geo_map_df.iterrows():\n",
        "    if pd.notnull(row[\"Unemployment_rate_2023\"]):\n",
        "        radius = 3 + (row[\"Unemployment_rate_2023\"] / max_unemp) * 20\n",
        "\n",
        "        intensity = row[\"Unemployment_rate_2023\"] / max_unemp\n",
        "        color = linear.OrRd_09.scale(\n",
        "            geo_map_df[\"Unemployment_rate_2023\"].min(),\n",
        "            geo_map_df[\"Unemployment_rate_2023\"].max()\n",
        "        )(row[\"Unemployment_rate_2023\"])\n",
        "\n",
        "        folium.CircleMarker(\n",
        "            location=[row[\"centroid_lat\"], row[\"centroid_lon\"]],\n",
        "            radius=radius,\n",
        "            color=None,\n",
        "            fill=True,\n",
        "            fill_color=color,\n",
        "            fill_opacity=0.7,\n",
        "            popup=f\"{row['NAME']}<br>Unemployment Rate: {row['Unemployment_rate_2023']:.1f}%\"\n",
        "        ).add_to(m)\n",
        "\n",
        "\n",
        "legend_html = \"\"\"\n",
        "<div style=\"\n",
        "     position: fixed; bottom: 40px; left: 40px; width:250px;\n",
        "     background:white; border:2px solid grey; z-index:9999;\n",
        "     font-size:14px; padding:10px; border-radius:12px;\">\n",
        "<b>Marker Legend</b><br>\n",
        "<span style=\"background: linear-gradient(to right, orange, red); width:40px; height:15px;\n",
        "      display:inline-block; margin-right:5px;\"></span> Unemployment Rate (circle size & color)\n",
        "</div>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "\n",
        "m.save(\"literacy_unemployment_map.html\")\n",
        "m\n"
      ],
      "metadata": {
        "id": "Cy0rkF3PvFic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZCyBCD6llb"
      },
      "source": [
        "## Data centers and water proximity\n",
        "\n",
        "Data centers are extremely water-intensive facilities, and their location decisions often align closely with access to reliable water sources. Cooling servers generates enormous heat, and many data centers rely on water-based cooling systems that can consume millions of gallons per day. As a result, regions with major rivers, aquifers, or stable freshwater infrastructure tend to attract more data-center development. However, this creates tension in areas already facing water scarcity or ecosystem stress. By comparing data-center locations with water sediment concentrations, we can explore whether environmental water quality—or proximity to specific water bodies—plays a role in where these facilities are being built. This analysis helps highlight potential sustainability risks and regional trade-offs tied to the rapid growth of digital infrastructure.\n",
        "\n",
        "Fun Fact:\n",
        "A single large data center can use between 3 million and 5 million gallons of water per day—roughly the same daily water consumption as a city of 30,000–50,000 people."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDCqYdxX16Sz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "usa_data = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "\n",
        "mainland_states = [\n",
        "    \"AL\",\"AR\",\"AZ\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\"IA\",\"ID\",\"IL\",\"IN\",\n",
        "    \"KS\",\"KY\",\"LA\",\"MA\",\"MD\",\"ME\",\"MI\",\"MN\",\"MO\",\"MS\",\"MT\",\"NC\",\"ND\",\n",
        "    \"NE\",\"NH\",\"NJ\",\"NM\",\"NV\",\"NY\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\"SD\",\n",
        "    \"TN\",\"TX\",\"UT\",\"VA\",\"VT\",\"WA\",\"WI\",\"WV\",\"WY\"\n",
        "]\n",
        "mainland_usa = usa_data[usa_data[\"STATE\"].isin(mainland_states)]\n",
        "\n",
        "dc_df = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "\n",
        "us_abbrev = {\n",
        "    \"Alabama\":\"AL\", \"Alaska\":\"AK\", \"Arizona\":\"AZ\", \"Arkansas\":\"AR\", \"California\":\"CA\", \"Colorado\":\"CO\",\n",
        "    \"Connecticut\":\"CT\", \"Delaware\":\"DE\", \"Florida\":\"FL\", \"Georgia\":\"GA\", \"Hawaii\":\"HI\", \"Idaho\":\"ID\",\n",
        "    \"Illinois\":\"IL\", \"Indiana\":\"IN\", \"Iowa\":\"IA\", \"Kansas\":\"KS\", \"Kentucky\":\"KY\", \"Louisiana\":\"LA\",\n",
        "    \"Maine\":\"ME\", \"Maryland\":\"MD\", \"Massachusetts\":\"MA\", \"Michigan\":\"MI\", \"Minnesota\":\"MN\",\n",
        "    \"Mississippi\":\"MS\", \"Missouri\":\"MO\", \"Montana\":\"MT\", \"Nebraska\":\"NE\", \"Nevada\":\"NV\",\n",
        "    \"New Hampshire\":\"NH\", \"New Jersey\":\"NJ\", \"New Mexico\":\"NM\", \"New York\":\"NY\", \"North Carolina\":\"NC\",\n",
        "    \"North Dakota\":\"ND\", \"Ohio\":\"OH\", \"Oklahoma\":\"OK\", \"Oregon\":\"OR\", \"Pennsylvania\":\"PA\",\n",
        "    \"Rhode Island\":\"RI\", \"South Carolina\":\"SC\", \"South Dakota\":\"SD\", \"Tennessee\":\"TN\", \"Texas\":\"TX\",\n",
        "    \"Utah\":\"UT\", \"Vermont\":\"VT\", \"Virginia\":\"VA\", \"Washington\":\"WA\", \"West Virginia\":\"WV\",\n",
        "    \"Wisconsin\":\"WI\", \"Wyoming\":\"WY\"\n",
        "}\n",
        "dc_df[\"STATE\"] = dc_df[\"State\"].map(us_abbrev)\n",
        "\n",
        "merged = mainland_usa.merge(dc_df, on=\"STATE\", how=\"left\")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "merged.plot(\n",
        "    column=\"DataCenters\",\n",
        "    cmap=\"Blues\",\n",
        "    linewidth=0.8,\n",
        "    edgecolor=\"black\",\n",
        "    legend=True,\n",
        "    vmin=0,\n",
        "    vmax=400,\n",
        "    legend_kwds={\n",
        "        \"label\": \"Number of Data Centers\",\n",
        "        \"orientation\": \"horizontal\",\n",
        "        \"shrink\": 0.6\n",
        "    },\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "ax.set_title(\"Data Center Distribution Across the U.S.\", fontsize=18, pad=20)\n",
        "ax.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkFPPc-FqhVG"
      },
      "outputs": [],
      "source": [
        "dc_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OqbbnJW_LEd"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "sediments = pd.read_csv(base_url + \"SedimentDatabase_Locations.csv\")\n",
        "\n",
        "usa_sed = sediments[sediments[\"Country\"].str.contains(\"USA\", na=False)].copy()\n",
        "usa_sed = usa_sed.dropna(subset=[\"Lat_deg\", \"Lon_deg\"])\n",
        "\n",
        "gdf_sed = gpd.GeoDataFrame(\n",
        "    usa_sed,\n",
        "    geometry=gpd.points_from_xy(usa_sed[\"Lon_deg\"], usa_sed[\"Lat_deg\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "gdf_sed_mainland = gpd.sjoin(gdf_sed, mainland_usa[[\"STATE\", \"geometry\"]], how=\"inner\", predicate=\"within\")\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 10))\n",
        "\n",
        "merged.plot(\n",
        "    column=\"DataCenters\",\n",
        "    cmap=\"Blues\",\n",
        "    linewidth=0.8,\n",
        "    edgecolor=\"black\",\n",
        "    legend=True,\n",
        "    legend_kwds={\n",
        "        \"label\": \"Number of Data Centers\",\n",
        "        \"orientation\": \"horizontal\",\n",
        "        \"shrink\": 0.6\n",
        "    },\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "gdf_sed_mainland.plot(\n",
        "    ax=ax,\n",
        "    color=\"red\",\n",
        "    markersize=20,\n",
        "    alpha=0.6,\n",
        "    label=\"Sediment / Water Sites\"\n",
        ")\n",
        "\n",
        "ax.set_title(\"Mainland U.S. Data Centers vs. Sediment (Water-Proximal) Locations\", fontsize=18, pad=20)\n",
        "ax.axis(\"off\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_xPkBoqyoSZ"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "from folium import Choropleth, LayerControl, FeatureGroup, CircleMarker\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "sediments = pd.read_csv(base_url + \"SedimentDatabase_Locations.csv\")\n",
        "usa_sed = sediments[sediments[\"Country\"].str.contains(\"USA\", na=False)].copy()\n",
        "usa_sed = usa_sed.dropna(subset=[\"Lat_deg\", \"Lon_deg\"])\n",
        "\n",
        "gdf_sed = gpd.GeoDataFrame(\n",
        "    usa_sed,\n",
        "    geometry=gpd.points_from_xy(usa_sed[\"Lon_deg\"], usa_sed[\"Lat_deg\"]),\n",
        "    crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "gdf_sed_mainland = gpd.sjoin(\n",
        "    gdf_sed,\n",
        "    mainland_usa[[\"STATE\", \"geometry\"]],\n",
        "    how=\"inner\",\n",
        "    predicate=\"within\"\n",
        ")\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"CartoDB positron\")\n",
        "\n",
        "Choropleth(\n",
        "    geo_data=merged.to_json(),\n",
        "    name=\"Data Centers by State\",\n",
        "    data=merged,\n",
        "    columns=[\"STATE\", \"DataCenters\"],\n",
        "    key_on=\"feature.properties.STATE\",\n",
        "    fill_color=\"Blues\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.3,\n",
        "    legend_name=\"Number of Data Centers\"\n",
        ").add_to(m)\n",
        "\n",
        "sediment_layer = FeatureGroup(name=\"Sediment / Water Sites\")\n",
        "\n",
        "for _, row in gdf_sed_mainland.iterrows():\n",
        "    CircleMarker(\n",
        "        location=[row.geometry.y, row.geometry.x],\n",
        "        radius=3,\n",
        "        color=\"red\",\n",
        "        fill=True,\n",
        "        fill_color=\"red\",\n",
        "        fill_opacity=0.5,\n",
        "        popup=f\"Site: {row.get('SiteName', 'N/A')}<br>State: {row['STATE']}\"\n",
        "    ).add_to(sediment_layer)\n",
        "\n",
        "sediment_layer.add_to(m)\n",
        "\n",
        "LayerControl(collapsed=False).add_to(m)\n",
        "\n",
        "title_html = \"\"\"\n",
        "<h3 align=\"center\" style=\"font-size:20px\">\n",
        "Mainland U.S. Data Centers vs. Sediment (Water-Proximal) Locations\n",
        "</h3>\n",
        "\"\"\"\n",
        "m.get_root().html.add_child(folium.Element(title_html))\n",
        "\n",
        "m\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhN-q9pSxchC"
      },
      "outputs": [],
      "source": [
        "electricity_df = pd.read_excel(base_url + \"generation_monthly.xlsx\")\n",
        "print(electricity_df.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsPRL9qo752y"
      },
      "outputs": [],
      "source": [
        "electricity_df[\"STATE\"].unique()[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3giLyWqe_x6"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "usa_states = gpd.read_file(\"data/usa_map/s_05mr24.shp\")\n",
        "usa_states = usa_states[~usa_states[\"NAME\"].isin([\"Hawaii\", \"Alaska\", \"Puerto Rico\"])]\n",
        "\n",
        "generation = pd.read_excel(base_url + \"generation_monthly.xlsx\")\n",
        "datacenters = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "\n",
        "\n",
        "us_state_map = {\n",
        "    'AL':'Alabama','AK':'Alaska','AZ':'Arizona','AR':'Arkansas','CA':'California',\n",
        "    'CO':'Colorado','CT':'Connecticut','DE':'Delaware','FL':'Florida','GA':'Georgia',\n",
        "    'HI':'Hawaii','ID':'Idaho','IL':'Illinois','IN':'Indiana','IA':'Iowa','KS':'Kansas',\n",
        "    'KY':'Kentucky','LA':'Louisiana','ME':'Maine','MD':'Maryland','MA':'Massachusetts',\n",
        "    'MI':'Michigan','MN':'Minnesota','MS':'Mississippi','MO':'Missouri','MT':'Montana',\n",
        "    'NE':'Nebraska','NV':'Nevada','NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico',\n",
        "    'NY':'New York','NC':'North Carolina','ND':'North Dakota','OH':'Ohio','OK':'Oklahoma',\n",
        "    'OR':'Oregon','PA':'Pennsylvania','RI':'Rhode Island','SC':'South Carolina',\n",
        "    'SD':'South Dakota','TN':'Tennessee','TX':'Texas','UT':'Utah','VT':'Vermont',\n",
        "    'VA':'Virginia','WA':'Washington','WV':'West Virginia','WI':'Wisconsin','WY':'Wyoming'\n",
        "}\n",
        "\n",
        "generation['State'] = generation['STATE'].map(us_state_map)\n",
        "\n",
        "generation_state = (\n",
        "    generation.groupby('State', as_index=False)['GENERATION (Megawatthours)']\n",
        "    .sum()\n",
        "    .rename(columns={'GENERATION (Megawatthours)': 'Generation_MWh'})\n",
        ")\n",
        "\n",
        "merged_df = pd.merge(datacenters, generation_state, on='State', how='left')\n",
        "\n",
        "\n",
        "merged_geo = usa_states.merge(merged_df, left_on=\"NAME\", right_on=\"State\", how=\"left\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUh0mQma4Ns_"
      },
      "outputs": [],
      "source": [
        "dc = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "\n",
        "dc.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mixft2jq8S72"
      },
      "source": [
        "## Data centers and land prices\n",
        "\n",
        "Data centers require huge footprints—not just for the servers, but also for cooling infrastructure, power distribution networks, and physical security buffers. Because of this, states with lower land prices often become hotspots for large-scale data center construction. Cheaper land directly reduces upfront capital expenditure and enables companies to build sprawling single-story facilities with room for future expansion. In contrast, states with expensive land tend to see fewer hyperscale facilities and more compact, high-rise data centers. This relationship between land cost and facility density is a major factor in where cloud providers choose to expand.\n",
        "\n",
        "Fun Fact:\n",
        "A typical hyperscale data center campus can require 100–250 acres of land to support server halls, cooling plants, substations, and redundancy systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RJxCkSd3-jn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import folium\n",
        "\n",
        "land = pd.read_csv(base_url + \"real_estate_values.csv\")\n",
        "dc = pd.read_csv(base_url + \"datacenter_counts_by_state.csv\")\n",
        "\n",
        "land[\"State\"] = land[\"State\"].str.strip()\n",
        "dc[\"State\"] = dc[\"State\"].str.strip()\n",
        "\n",
        "merged = land.merge(dc, on=\"State\")\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json\"\n",
        "states_gdf = gpd.read_file(url)\n",
        "\n",
        "states_gdf[\"name\"] = states_gdf[\"name\"].str.strip()\n",
        "\n",
        "geo_merged = states_gdf.merge(merged, left_on=\"name\", right_on=\"State\")\n",
        "\n",
        "m = folium.Map(location=[37.8, -96], zoom_start=5)\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=geo_merged,\n",
        "    name=\"Land Price per Acre\",\n",
        "    data=geo_merged,\n",
        "    columns=[\"State\", \"Price_per_Acre\"],\n",
        "    key_on=\"feature.properties.name\",\n",
        "    fill_color=\"YlOrRd\",\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name=\"Land Price Per Acre (USD)\"\n",
        ").add_to(m)\n",
        "\n",
        "\n",
        "for _, row in geo_merged.iterrows():\n",
        "    centroid = row[\"geometry\"].centroid\n",
        "    folium.CircleMarker(\n",
        "        location=[centroid.y, centroid.x],\n",
        "        radius=max(row[\"DataCenters\"]*0.08, 2),   # scale bubble size\n",
        "        popup=f\"{row['State']}: {row['DataCenters']} Data Centers\",\n",
        "        fill=True,\n",
        "        fill_opacity=0.8\n",
        "    ).add_to(m)\n",
        "m.save(\"data_centers_and _land_prices.html\")\n",
        "m\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QCFsu3G7at9"
      },
      "source": [
        "Virginia, Texas, and California have the most data centers in the U.S., largely because of Virginia's proximity to government agencies and dense fiber optics in the \"Data Center Alley\" near Washington D.C., Texas's central location and lower costs, and California's concentration of tech companies in Silicon Valley. Other factors include the availability of land, power, water, and favorable tax incentives in many of these locations.\n",
        "\n",
        "1.  **Virginia**\n",
        "    *   **Proximity to government and dense fiber:** Northern Virginia, specifically \"Data Center Alley\" in Loudoun County, is the top hub due to its close ties with federal government agencies and a dense network of fiber optic cables.\n",
        "    *   **Connectivity:** The region has four subsea fiber cables terminating there, providing direct connectivity to global markets.\n",
        "    *   **Other advantages:** There is a skilled workforce, available land, and robust power and water supplies to support operations.\n",
        "\n",
        "2.  **Texas**\n",
        "    *   **Strategic location:** Primarily concentrated in the Dallas/Forth Worth area, Texas benefits from being a central hub for the nation.\n",
        "    *   **Cost-effectiveness:** The state offers a lower cost of land and operations compared to coastal hubs.\n",
        "    *   **Economic development:** Many states, including Texas, have created economic development zones to attract data centers.\n",
        "\n",
        "3.  **California**\n",
        "    *   **Silicon Valley hub:** California's high concentration of data centers is centered in Silicon Valley, a major technology hub.\n",
        "    *   **Existing infrastructure:** The state has a high demand for data services from tech companies.\n",
        "    *   **Drawbacks:** Despite the high concentration, California faces challenges like higher costs and regulatory hurdles.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "df = merged.copy()\n",
        "\n",
        "price_med = df['Price_per_Acre'].median()\n",
        "dc_med = df['DataCenters'].median()\n",
        "\n",
        "def classify(row):\n",
        "    if row['Price_per_Acre'] >= price_med and row['DataCenters'] >= dc_med:\n",
        "        return \"High Price / High Count\"\n",
        "    elif row['Price_per_Acre'] >= price_med and row['DataCenters'] < dc_med:\n",
        "        return \"High Price / Low Count\"\n",
        "    elif row['Price_per_Acre'] < price_med and row['DataCenters'] >= dc_med:\n",
        "        return \"Low Price / High Count\"\n",
        "    else:\n",
        "        return \"Low Price / Low Count\"\n",
        "\n",
        "df['Quadrant'] = df.apply(classify, axis=1)\n",
        "\n",
        "fig = px.scatter(\n",
        "    df,\n",
        "    x=\"Price_per_Acre\",\n",
        "    y=\"DataCenters\",\n",
        "    color=\"Quadrant\",\n",
        "    hover_name=\"State\",\n",
        "    hover_data={\n",
        "        \"Price_per_Acre\": True,\n",
        "        \"DataCenters\": True,\n",
        "        \"Quadrant\": True\n",
        "    },\n",
        "    color_discrete_sequence=px.colors.qualitative.Pastel,\n",
        "    height=700,\n",
        "    size=[12] * len(df)\n",
        ")\n",
        "\n",
        "fig.add_vline(x=price_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "fig.add_hline(y=dc_med, line_dash=\"dash\", line_color=\"gray\")\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"Land Price per Acre vs Datacenter Count — Quadrant Classifier\",\n",
        "    xaxis_title=\"Land Price per Acre ($)\",\n",
        "    yaxis_title=\"Number of Datacenters\",\n",
        "    plot_bgcolor=\"rgba(245,245,245,0.3)\",\n",
        "    legend_title=\"Quadrant\"\n",
        ")\n",
        "\n",
        "fig.write_html(\"land_price_vs_datacenters.html\")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "XzBQtgOtv1qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count-wise internet connection meeting"
      ],
      "metadata": {
        "id": "-2tqZkOG6Mzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "geojson_url = \"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\"\n",
        "county_geojson = requests.get(geojson_url).json()"
      ],
      "metadata": {
        "id": "iry8pIQT8gi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(base_url + \"county_connections_200906_202406.csv\", encoding=\"cp1252\")\n",
        "df[\"countycode\"] = df[\"countycode\"].astype(str).str.zfill(5)\n",
        "\n",
        "latest = df[df[\"year\"] == 2024]"
      ],
      "metadata": {
        "id": "3o4O_zui8oNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest.head()"
      ],
      "metadata": {
        "id": "19LwxaN7_QsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest[\"all\"] = pd.to_numeric(latest[\"all\"], errors=\"coerce\")\n",
        "latest.loc[latest[\"all\"] < 0, \"all\"] = None"
      ],
      "metadata": {
        "id": "SR8KDZ_D9DHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "bins = list(latest[\"all\"].quantile([0, 0.25, 0.5, 0.75, 1]))\n"
      ],
      "metadata": {
        "id": "7xYhJos79I51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = folium.Map(location=[37.8, -96], zoom_start=4, tiles=\"cartodbpositron\")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=county_geojson,\n",
        "    data=latest,\n",
        "    columns=[\"countycode\", \"all\"],\n",
        "    key_on=\"feature.id\",\n",
        "    fill_color=\"RdPu\",\n",
        "    fill_opacity=0.8,\n",
        "    line_opacity=0.2,\n",
        "    bins=bins,\n",
        "    nan_fill_color=\"lightgray\",\n",
        "    legend_name=\"High-Speed Internet Connections (000s)\",\n",
        "    reset=True\n",
        ").add_to(m)\n",
        "\n",
        "m.save(\"internet_usage_county_map.html\")\n",
        "m\n"
      ],
      "metadata": {
        "id": "SFuA3XAu9LxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"internet_usage_county_map.html\")"
      ],
      "metadata": {
        "id": "wPg5RigZ-P4u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}